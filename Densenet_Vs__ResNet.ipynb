{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Densenet_Vs._ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYK8ZgCil+fnwi6KfNErNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/AI_booklet_CE-AUT/blob/master/Densenet_Vs__ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWheA6CSj3ft"
      },
      "source": [
        "# **Mount google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r3444wwj6Mr",
        "outputId": "04c2a445-dc7c-4034-e1d6-f7ed968ef82e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTSvl-QYjyo3"
      },
      "source": [
        "# **prerequisit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3bPfRvshs1o"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input, GlobalAveragePooling2D, Dropout ,  BatchNormalization\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "import os\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjMMgNOLkSzX"
      },
      "source": [
        "# **Make dataset ready**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97QoNMEWkXoZ",
        "outputId": "19a587db-86c1-4904-fcf3-a35ac5206030"
      },
      "source": [
        "def load_photos(type,dir_name):\n",
        "    photo_list =[]\n",
        "    y = []\n",
        "    for file_name in (glob.glob(dir_name+'/*')):\n",
        "        img = image.load_img(file_name, target_size=input_size)\n",
        "        img = np.array(img)\n",
        "        photo_list.append(img)\n",
        "        y.append(type)\n",
        "    return photo_list , y \n",
        "  \n",
        "    \n",
        "input_size = (128,128)\n",
        "input_shape = (128,128,3)\n",
        "dir_name_indoor = \"/content/drive/MyDrive/Colab Notebooks/indoor\"\n",
        "dir_name_outdoor = \"/content/drive/MyDrive/Colab Notebooks/outdoor\"\n",
        "X1 , y1= load_photos(0,dir_name_indoor) \n",
        "X2 , y2= load_photos(1,dir_name_outdoor) \n",
        "X1.extend(X2)\n",
        "y1.extend(y2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.1, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[132 135 114]\n",
            " [132 135 114]\n",
            " [130 133 112]\n",
            " [131 134 113]\n",
            " [131 134 113]\n",
            " [134 137 116]\n",
            " [132 135 114]\n",
            " [132 135 114]\n",
            " [134 137 116]\n",
            " [134 137 116]\n",
            " [134 137 116]\n",
            " [134 137 116]\n",
            " [134 137 116]\n",
            " [132 135 114]\n",
            " [132 135 114]\n",
            " [132 135 114]\n",
            " [131 134 113]\n",
            " [135 138 117]\n",
            " [135 138 117]\n",
            " [123 131 107]\n",
            " [135 143 119]\n",
            " [119 127 103]\n",
            " [135 135 123]\n",
            " [178 178 166]\n",
            " [223 223 211]\n",
            " [245 245 233]\n",
            " [235 246 242]\n",
            " [243 254 250]\n",
            " [227 238 234]\n",
            " [228 239 231]\n",
            " [213 224 216]\n",
            " [194 205 197]\n",
            " [168 182 157]\n",
            " [135 149 124]\n",
            " [118 132 107]\n",
            " [119 127 104]\n",
            " [119 127 104]\n",
            " [118 126 103]\n",
            " [118 126 103]\n",
            " [118 126 103]\n",
            " [116 124 101]\n",
            " [116 124 101]\n",
            " [116 124 101]\n",
            " [114 122  99]\n",
            " [114 122  99]\n",
            " [116 124 101]\n",
            " [114 122  99]\n",
            " [114 122  99]\n",
            " [109 121  97]\n",
            " [109 121  97]\n",
            " [109 121  97]\n",
            " [111 123  99]\n",
            " [111 123  99]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [109 121  97]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  95]\n",
            " [107 119  97]\n",
            " [107 119  97]\n",
            " [105 117  95]\n",
            " [105 117  95]\n",
            " [105 117  95]\n",
            " [105 117  95]\n",
            " [103 120  86]\n",
            " [103 120  86]\n",
            " [103 120  86]\n",
            " [103 120  86]\n",
            " [107 118  86]\n",
            " [107 118  86]\n",
            " [107 118  86]\n",
            " [102 117  84]\n",
            " [104 119  86]\n",
            " [104 119  86]\n",
            " [102 117  84]\n",
            " [102 117  84]\n",
            " [102 117  84]\n",
            " [100 116  80]\n",
            " [100 116  80]\n",
            " [100 116  80]\n",
            " [ 97 117  80]\n",
            " [ 97 117  80]\n",
            " [ 97 117  80]\n",
            " [ 97 117  80]\n",
            " [ 96 119  73]\n",
            " [ 95 118  72]\n",
            " [ 95 118  72]\n",
            " [ 91 120  72]\n",
            " [ 90 119  71]\n",
            " [ 86 115  67]\n",
            " [ 94 115  72]\n",
            " [ 94 115  72]\n",
            " [ 93 114  71]\n",
            " [ 90 112  73]\n",
            " [ 87 109  70]\n",
            " [ 89 111  72]\n",
            " [ 92 113  72]\n",
            " [ 91 112  71]\n",
            " [ 80 101  60]\n",
            " [ 74  95  54]\n",
            " [ 50  64  41]\n",
            " [ 41  55  32]\n",
            " [ 35  49  26]\n",
            " [ 42  53  23]\n",
            " [ 31  42  12]\n",
            " [ 38  49  19]\n",
            " [ 34  50  11]\n",
            " [ 46  62  23]\n",
            " [ 68  84  45]\n",
            " [ 69  97  49]\n",
            " [ 67  95  47]\n",
            " [ 69  97  49]\n",
            " [ 79  95  56]\n",
            " [ 76  92  53]\n",
            " [ 76  92  53]\n",
            " [ 73  89  50]\n",
            " [ 72  88  52]\n",
            " [ 69  85  49]\n",
            " [ 69  85  49]\n",
            " [ 69  79  52]\n",
            " [ 67  77  50]\n",
            " [ 67  77  50]]\n",
            "800\n",
            "[1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1\n",
            " 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
            " 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 1\n",
            " 1 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 1 1 1\n",
            " 0 0 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 1 1 1 1 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0\n",
            " 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1\n",
            " 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0\n",
            " 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1\n",
            " 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1\n",
            " 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0\n",
            " 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1\n",
            " 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 0 0 1 0\n",
            " 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0\n",
            " 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBRdjt5g5FDD"
      },
      "source": [
        "# **ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYvr1RCd5KJQ"
      },
      "source": [
        "# keras.backend.clear_session()\n",
        "\n",
        "# inputs = keras.Input(shape=input_shape)\n",
        "# x = keras.applications.resnet.preprocess_input(inputs)\n",
        "# base_model = keras.applications.ResNet152(include_top=False, weights=\"imagenet\")\n",
        "# base_model.trainable = False\n",
        "# x = base_model(x) \n",
        "# # x = Flatten()(x)\n",
        "# x = Dense(1000, activation='ReLU')(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Dense(250, activation='ReLU')(x)\n",
        "# x = Dense(50, activation='ReLU')(x)\n",
        "# x = Dense(10, activation='ReLU')(x)\n",
        "# outputs = Dense(2, activation='softmax')(x)\n",
        "# # outputs = GlobalAveragePooling2D()(x) \n",
        "\n",
        "# resnet_model = keras.Model(inputs, outputs)\n",
        "# resnet_model.summary()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHub-nMJFUEE"
      },
      "source": [
        "# # Inputs\n",
        "# inputs = Input(shape=(128,128,3))\n",
        "# # ResNet\n",
        "# resnet152 = keras.applications.ResNet152(include_top=False, weights='imagenet')(inputs)\n",
        "# # Our FC layer\n",
        "# flat1 = Flatten()(resnet152)\n",
        "# dense1 = Dense(units=128, use_bias=True)(flat1)\n",
        "# batchnorm1 = BatchNormalization()(dense1)\n",
        "# # Output\n",
        "# out = Dense(units=1, activation='sigmoid')(batchnorm1)\n",
        "# # Create Model\n",
        "# model = keras.Model(inputs=inputs, outputs=out)\n",
        "# model.summary()\n",
        "# # model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edhsqUClIJQ6"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "base_model = keras.applications.ResNet152(include_top=False, weights=\"imagenet\",  input_shape=input_shape)\n",
        "base_model.trainable  = False\n",
        "model_res = Sequential()\n",
        "model_res.add(base_model)\n",
        "model_res.add(Flatten())\n",
        "model_res.add(Dense(1024,activation='relu'))\n",
        "# model_res.add(Dropout(0.2))\n",
        "model_res.add(Dense(350,activation='relu'))\n",
        "# model_res.add(Dropout(0.1))\n",
        "model_res.add(Dense(128,activation='relu'))\n",
        "# model_res.add(Dropout(0.1))\n",
        "model_res.add(Dense(35,activation='relu'))\n",
        "model_res.add(Dense(10,activation='relu'))\n",
        "model_res.add(Dense(2))\n",
        "# tf.keras.utils.plot_model(model_res,show_shapes=True,expand_nested=True)\n",
        "\n",
        " "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4wV1PYdcCs"
      },
      "source": [
        "# %rm -rf \"/content/drive/Mydrive/Colab Notebooks/logs\"\n",
        "import shutil\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")\n",
        "# shutil.rmtree('./logs')\n",
        "os.mkdir(\"./logs\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DhO1ZV4OQOH",
        "outputId": "4b767140-bb0e-4a1c-a8a2-93b0b612bf38"
      },
      "source": [
        "tb_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\",histogram_freq=1)\n",
        "model_res.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "model_res.fit(X_train,y_train,epochs=50,validation_split=0.2,callbacks=[tb_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer ModuleWrapper has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 124s 6s/step - loss: 7.7226 - accuracy: 0.6839 - val_loss: 0.3737 - val_accuracy: 0.9097\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 0.1040 - accuracy: 0.9711 - val_loss: 0.4963 - val_accuracy: 0.9167\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 0.0488 - accuracy: 0.9857 - val_loss: 0.5687 - val_accuracy: 0.9097\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.6053 - val_accuracy: 0.9028\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6632 - val_accuracy: 0.9097\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 7.8460e-04 - accuracy: 1.0000 - val_loss: 0.6575 - val_accuracy: 0.9097\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 1.2182e-04 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.9097\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 1.2077e-04 - accuracy: 1.0000 - val_loss: 0.6649 - val_accuracy: 0.9097\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 1.2286e-04 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.9097\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 1.0400e-04 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.9097\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 8.7704e-05 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.9097\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 8.6453e-05 - accuracy: 1.0000 - val_loss: 0.6829 - val_accuracy: 0.9097\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 6.6605e-05 - accuracy: 1.0000 - val_loss: 0.6859 - val_accuracy: 0.9097\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 5.5011e-05 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.9097\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 5.1965e-05 - accuracy: 1.0000 - val_loss: 0.6930 - val_accuracy: 0.9097\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 5.1942e-05 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.9097\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 5.4373e-05 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.9097\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 3.3777e-05 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.9097\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 3.6142e-05 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.9097\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 2.6447e-05 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.9097\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 104s 6s/step - loss: 2.1656e-05 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.9097\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 103s 6s/step - loss: 3.1140e-05 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.9097\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - ETA: 0s - loss: 2.8716e-05 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RMol8yyPoDk"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}